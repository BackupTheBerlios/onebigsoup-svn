
= 2005-06-04 =

== 6:23 PM ==

Been working on this for a while today. Got distracted by web (damn the
web!) and working on the MachineCodeBlocks today. But other than that,
it's been good today.

I'm about to commit the code, because I'm making a risky change: In
lnlink, I'm adding a class to assist in the names-collection and linking
process. It'll help keep track of a list of names to be linked, to link
them, to make sure you don't double-link (or allow you to re-link,)
something that helps you see what you've forgotten to link, and then
something that will link things that aren't linked yet to a
default.

That kind of stuff.

I think it'll help simplify the builder, and make things more friendly
all around.

Damn, I wish PEAK were well documented and mainstream. I see so many
ways to use it.


= 2005-06-03 =

== 6:32 PM ==

Okay, I think I've fixed the bug, I just need a test situation...

== 8:38 AM ==

Very briefly: I did a lot of work on it this morning, I got the
WebsiteBuilder.compile_names_dictionary working.

It's going well.

I have a bug to fix:

* lnlink is treating http://... as if it were a Local Name.


= 2005-06-02 =

== 12:50 AM ==

Shoot, it's too late. Anyways:

I need to put the recommended terms & languages notes in here. Or
somewhere. Maybe in the base directory? Maybe in some "direction"
directory, or with all the standards specifications, or..?

== 9:45 AM ==

It's going pretty well, so far. I've got the filesystem all abstracted
away. Now I'm working on the "SiteBuilder" class, moving in the contents
from __name__=='__main__' into there.


== 8:50 AM ==

Reworking to use the filesystem abstraction. I think I'm going to have
it just read some of the autostart files, and store them in
variables. No need to revisit them.


= 2005-06-01 =

== 8:21 PM ==

Okay, I'm back from working on SinghText. I believe we have everything
we need from over there- we can get a list of names in a given page, we
can make <a name='foo'>, we can do all these different things.

Now I just need to figure out what I need to do up here.

* I believe I was supposed to apply some filesystem abstraction in
  render.py.
* I believe it was supposed to use optparse.

So, let's take these in the following order:

# Rework to use filesystem abstraction.
# Setup optparse use.
# Start making it work.
** Build internal names table.
*** From pre-existing list.
*** Provided by pages. ($name)
*** ...and then those that are looked up from the Internet.
** Perform merging and collections and linking and whatnot.

So, I guess whenever I next get to code, it's reworking to the
filesystem abstraction that's up.


= 2005-05-30 =

== 2:23 PM ==

Uploading everything in the SVN tree. Arranging files, folders, text, ...

Renaming and repositioning some stuff, it'll be broken for a bit.


= 2005-05-25 =

== 9:56 AM ==

kw: todo

I need to make it so that localnames.txt is copied to the final
directory..!

== 9:53 AM ==

I need to make it an official part of the query spec, that names can be
relative addresses.

If a name does not begin with a protocol, then it is a relative address.

I need to figure out the formal basis for relative addressing off of
URLs, though, if there even is one.

== ~9:30 AM ==

lnlink and singhtext are now in the onebigsoup tree.

I want this whole space into there, with time.

I've been thinking: I can use a dictionary to store the names
binding. If something isn't found in the dictionary, THEN defer to the
network.

Or, read the names binding from the file, using the parser.

At any rate, the basic idea should work.


= 2005-05-25 =

PROBLEM:

* You have a program that makes use of several web pages, located
  all around the Internet.

* You run this program several times in a row. You also make use of
  other programs that may make use of web pages around the Internet,
  visiting the same (but also some different) pages.

* You want to cache your pulls- you don't want to keep pulling in
  the data, over and over and over again.

WHAT DO YOU DO,
  WHAT ''DO'' YOU DO?!?

SUPERPROBLEM:
 * I'm trying to resolve localnames from a text file that's not on the
   Internet.


possible solutions:
* Manually localnames.txt to the Internet before using it.
* Automaticall post localnames.txt, somehow, to the Internet, before
  using it.
* Post localnames.txt using the LN Store interface, before using it.
* Don't include localnames.txt as part of the website generation code.
* Write a resolver that works with local files, and can also defer to a
  remote names server.
* Extend the query interface to handle "here's a namespace's text" as
  part of a query.

I think I'll go with the namespace store.

